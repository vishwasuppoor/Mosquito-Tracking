{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import scipy.io\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline to prepare data and get train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract frames from video and resize to lower resolution\n",
    "# filename: video file name of .MOV format\n",
    "# size: tuple(w*h)\n",
    "# color: color or gray\n",
    "# saveHQ: True if full res frames need to be saved\n",
    "def vid2frames(filename, vidformat, size=(192,108), color=True, saveHQ=False):\n",
    "    if not os.path.exists('Frames_resize/'+filename):\n",
    "        os.makedirs('Frames_resize/'+filename)\n",
    "        vidcap = cv2.VideoCapture('video/'+filename+vidformat)\n",
    "        success,image = vidcap.read()\n",
    "        count = 0\n",
    "        while success:\n",
    "            if color:\n",
    "                img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            else:\n",
    "                img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            img = (cv2.resize(img, size, interpolation=cv2.INTER_CUBIC))\n",
    "            if saveHQ:\n",
    "                if not os.path.exists('Frames/'+filename):\n",
    "                    os.makedirs('Frames/'+filename)\n",
    "                cv2.imwrite('Frames/'+filename+'/frame%sd.jpg' % count, image)     # save frame as JPEG file\n",
    "            cv2.imwrite('Frames_resize/'+filename+'/frame%d.jpg' % count, img)     # save frame as JPEG file \n",
    "            success,image = vidcap.read()\n",
    "            count += 1\n",
    "        print(count,'frames were generated')\n",
    "\n",
    "# Load all gray/color images into a 4d array(num_blocks,5,h,w)/5d array(num_blocks,3,5,h,w)\n",
    "# filename: video name\n",
    "# chunklen: temporal dimension\n",
    "# size: tuple(w*h)\n",
    "# lowres: if True, uses the resized images\n",
    "# color: whether or not to use color channels\n",
    "def frames2np(filename, chunklen, size=(192,108), lowres=True, color=True):\n",
    "    dim = 5 if color else 4\n",
    "    quality = 'lq' if lowres else 'hq'\n",
    "    if not os.path.isfile('data/train/'+filename+'_cl'+str(chunklen)+'_'+str(dim)+'d'+'_'+quality+'.npy'):        \n",
    "        if lowres:\n",
    "            path = 'Frames_resize/'+filename\n",
    "        else:\n",
    "            path = 'Frames/'+filename\n",
    "        filelist = sorted(glob.glob(os.path.join(path,'*.jpg')),key=lambda stri: int(re.findall('\\d+', stri)[0]))\n",
    "        num_chunks = len(filelist)//chunklen\n",
    "        filelist = filelist[:num_chunks*chunklen]\n",
    "        if color:\n",
    "            vid_np = np.zeros((num_chunks,chunklen,size[1],size[0],3))\n",
    "        else:\n",
    "            vid_np = np.zeros((num_chunks,chunklen,size[1],size[0]))\n",
    "        i = 0\n",
    "        j = 0\n",
    "        for frame in filelist:\n",
    "            if color:\n",
    "                image = cv2.imread(frame, cv2.IMREAD_COLOR)\n",
    "            else:\n",
    "                image = cv2.imread(frame, cv2.IMREAD_GRAYSCALE)\n",
    "            vid_np[i,j] = image\n",
    "            j += 1\n",
    "            if j % chunklen == 0:\n",
    "                j = 0\n",
    "                i += 1\n",
    "        if color:\n",
    "            vid_np = vid_np.reshape((num_chunks,3,chunklen,size[1],size[0]))\n",
    "        np.save('data/train/'+filename+'_cl'+str(chunklen)+'_'+str(dim)+'d'+'_'+quality,vid_np)\n",
    "        print('shape of numpy:',vid_np.shape)\n",
    "    else:\n",
    "        vid_np = np.load('data/train/'+filename+'_cl'+str(chunklen)+'_'+str(dim)+'d'+'_'+quality+'.npy')\n",
    "    return vid_np.shape[0]\n",
    "\n",
    "# generate 0 1 labels from framenums\n",
    "# filename: video name\n",
    "# chunklen: temporal dimension\n",
    "# numchunks: data size\n",
    "def framenum2labels(filename, chunklen, numchunks, csvformat=True):\n",
    "    if not os.path.isfile('labels/train/'+filename+'_cl'+str(chunklen)+'.npy'):\n",
    "        numframes = numchunks*chunklen\n",
    "        if not csvformat:\n",
    "            mat = scipy.io.loadmat('labels/'+filename+'.mat')\n",
    "            try:\n",
    "                framenums = np.array(mat['labels'][0])\n",
    "            except:\n",
    "                framenums = np.array(mat['frames'][0])\n",
    "            framelabels = np.zeros(numframes)\n",
    "            framelabels[framenums-1] = 1\n",
    "        else:\n",
    "            framelabels = []\n",
    "            with open('labels/'+filename+'.csv') as csvfile:\n",
    "                reader = csv.reader(csvfile)\n",
    "                for row in reader:\n",
    "                    framelabels.append(int(re.sub(\"\\D\", \"\", row[0])))\n",
    "            framelabels = np.array(framelabels[:numframes])\n",
    "        labels = 2*np.ones(numchunks)\n",
    "        for i in range(chunklen,numframes+chunklen,chunklen):\n",
    "            if np.sum(framelabels[i-chunklen:i]) > 0:\n",
    "                labels[i//chunklen-1] = 1\n",
    "            else:\n",
    "                labels[i//chunklen-1] = 0\n",
    "        np.save('labels/train/'+filename+'_cl'+str(chunklen),labels)\n",
    "        print('shape of labels:',labels.shape)\n",
    "\n",
    "# split the data into training and validation sets\n",
    "# filename: numpy file name without d\n",
    "# trainsplit: portion of training data\n",
    "# dim: 4 or 5\n",
    "def split(filename,trainsplit,dim,quality):\n",
    "    npfile = np.load('data/train/'+filename+'_'+str(dim)+'d'+'_'+quality+'.npy')\n",
    "    label = np.load('labels/train/'+filename+'.npy')\n",
    "    if trainsplit < 1 and trainsplit > 0:\n",
    "        size = len(npfile)\n",
    "        trainbatch = int(size*trainsplit)\n",
    "        indices = np.random.permutation(size)\n",
    "        npfile = npfile[indices]\n",
    "        label = label[indices]\n",
    "        train_data = npfile[:trainbatch]\n",
    "        train_labels = label[:trainbatch]\n",
    "        validation_data = npfile[trainbatch:]\n",
    "        validation_labels = label[trainbatch:]\n",
    "        np.save('data/train/'+filename+'_'+str(dim)+'d_'+quality+'_'+str(trainsplit), train_data)\n",
    "        np.save('data/validation/'+filename+'_'+str(dim)+'d_'+quality+'_'+str(trainsplit), validation_data)\n",
    "        np.save('labels/train/'+filename+'_'+str(trainsplit),train_labels)\n",
    "        np.save('labels/validation/'+filename+'_'+str(trainsplit),validation_labels)      \n",
    "        print('train shape:',train_data.shape, 'validation shape:',validation_data.shape)\n",
    "\n",
    "# runs the video and label throught he pipeline to produce training and validation datasets\n",
    "# by default, no validation dataset is generated\n",
    "# csv: True if the labels are in a csv\n",
    "def prepdata(filename, vidformat, chunklen, trainsplit=1, size=(192,108), csvformat=True, color=True, saveHQ=False, lowres=True):\n",
    "    vid2frames(filename, vidformat=vidformat, size=size, color=color, saveHQ=saveHQ)\n",
    "    numchunks = frames2np(filename, chunklen, size=size, lowres=lowres, color=color)\n",
    "    framenum2labels(filename, chunklen, numchunks, csvformat=csvformat)\n",
    "    if trainsplit != 1:\n",
    "        filename = filename+'_cl'+str(chunklen)\n",
    "        dim = 5 if color else 4\n",
    "        quality = 'lq' if lowres else 'hq'\n",
    "        split(filename,trainsplit,dim,quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function to translate predictions to time for qualitative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred2time(predictions, chunk_len=5, fps=30):\n",
    "    times = np.where(predictions == predictions)[0] * chunk_len // fps\n",
    "    times = times[predictions == 1]\n",
    "    return times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appenddata(filename1,filename2,chunklen,dim,quality,trainsplit=1):\n",
    "    if trainsplit != 1:\n",
    "        file1 = np.load('data/train/'+filename1+'_cl'+str(chunklen)+'_'+str(dim)+'d_'+quality+'_'+str(trainsplit)+'.npy')\n",
    "        file2 = np.load('data/train/'+filename2+'_cl'+str(chunklen)+'_'+str(dim)+'d_'+quality+'_'+str(trainsplit)+'.npy')\n",
    "        label1 = np.load('labels/train/'+filename1+'_cl'+str(chunklen)+'_'+str(trainsplit)+'.npy')\n",
    "        label2 = np.load('labels/train/'+filename2+'_cl'+str(chunklen)+'_'+str(trainsplit)+'.npy')\n",
    "        validation1 = np.load('data/validation/'+filename1+'_cl'+str(chunklen)+'_'+str(dim)+'d_'+quality+'_'+str(trainsplit)+'.npy')\n",
    "        validation2 = np.load('data/validation/'+filename2+'_cl'+str(chunklen)+'_'+str(dim)+'d_'+quality+'_'+str(trainsplit)+'.npy')\n",
    "        vlabel1 = np.load('labels/validation/'+filename1+'_cl'+str(chunklen)+'_'+str(trainsplit)+'.npy')\n",
    "        vlabel2 = np.load('labels/validation/'+filename2+'_cl'+str(chunklen)+'_'+str(trainsplit)+'.npy')\n",
    "    else:\n",
    "        file1 = np.load('data/train/'+filename1+'_cl'+str(chunklen)+'_'+str(dim)+'d_'+quality+'.npy')\n",
    "        file2 = np.load('data/train/'+filename2+'_cl'+str(chunklen)+'_'+str(dim)+'d_'+quality+'.npy')\n",
    "        label1 = np.load('labels/train/'+filename1+'_cl'+str(chunklen)+'.npy')\n",
    "        label2 = np.load('labels/train/'+filename2+'_cl'+str(chunklen)+'.npy')\n",
    "    np.save('data/train/'+filename1+'_'+filename2+'_cl'+str(chunklen)+'_'+str(dim)+'d_'+quality+'_'+str(trainsplit),np.append(file1, file2, axis=0))\n",
    "    np.save('labels/train/'+filename1+'_'+filename2+'_cl'+str(chunklen)+'_'+str(trainsplit),np.append(label1, label2, axis=0))\n",
    "    np.save('data/validation/'+filename1+'_'+filename2+'_cl'+str(chunklen)+'_'+str(dim)+'d_'+quality+'_'+str(trainsplit),np.append(validation1, validation2, axis=0))\n",
    "    np.save('labels/validation/'+filename1+'_'+filename2+'_cl'+str(chunklen)+'_'+str(trainsplit),np.append(vlabel1, vlabel2, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of labels: (629,)\n",
      "train shape: (503, 5, 108, 192) validation shape: (126, 5, 108, 192)\n"
     ]
    }
   ],
   "source": [
    "prepdata('MVI_7500','.mov',5,0.8,color=False,csvformat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of numpy: (932, 5, 108, 192)\n",
      "shape of labels: (932,)\n",
      "train shape: (745, 5, 108, 192) validation shape: (187, 5, 108, 192)\n"
     ]
    }
   ],
   "source": [
    "prepdata('MVI_7503','.mov',5,0.8,color=False,csvformat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of numpy: (598, 5, 108, 192)\n",
      "shape of labels: (598,)\n",
      "train shape: (478, 5, 108, 192) validation shape: (120, 5, 108, 192)\n"
     ]
    }
   ],
   "source": [
    "prepdata('MVI_7512','.mov',5,0.8,color=False,csvformat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "appenddata('MVI_7500','MVI_7503',5,4,'lq',0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of numpy: (342, 5, 108, 192)\n",
      "shape of labels: (342,)\n",
      "train shape: (273, 5, 108, 192) validation shape: (69, 5, 108, 192)\n"
     ]
    }
   ],
   "source": [
    "prepdata('youtube1','.mp4',5,0.8,color=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of numpy: (199, 5, 108, 192)\n",
      "shape of labels: (199,)\n",
      "train shape: (159, 5, 108, 192) validation shape: (40, 5, 108, 192)\n"
     ]
    }
   ],
   "source": [
    "prepdata('first','.mov',5,0.8,color=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('predictions/youtube1_cl5_4d_lq_0.8.npy')\n",
    "b = np.load('labels/test/youtube1_cl5_0.8.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "       0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
       "       1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       0.])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       0.])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    print('yes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

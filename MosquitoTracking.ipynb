{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import scipy.io\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline to prepare data and get train/validation split\n",
    "#### prepdata(filename, vidformat, chunklen, threshold=1, trainsplit=1, size=(192,108), csvformat=True, color=True, saveHQ=False, lowres=True)  \n",
    "filename: video file name  \n",
    "vidformat: format like avi/mov/mp4  \n",
    "chunklen: number of frames/chunk of video  \n",
    "threshold: min number of frames in a chunk where mosquito must be present to label as positive sample  \n",
    "trainsplit: train_data / total_data  \n",
    "size: resolution of saved data  \n",
    "csvformat: True if csv, False if mat  \n",
    "color: if True, color channels are retained, results in 5d data. Else data is 4d without color channels  \n",
    "saveHQ: if True, full resolution images are also saved. Required for qualitative analysis of predictions  \n",
    "lowres: if True, uses low resolution images to prepare data. Use to save memory  \n",
    "#### Eg: prepdata('MVI_7500','.mov',5,1,0.8,color=False,csvformat=False,saveHQ=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract frames from video and resize to lower resolution\n",
    "# filename: video file name of .MOV format\n",
    "# size: tuple(w*h)\n",
    "# color: color or gray\n",
    "# saveHQ: True if full res frames need to be saved\n",
    "def vid2frames(filename, vidformat, size=(192,108), color=True, saveHQ=False):\n",
    "    if not os.path.exists('Frames_resize/'+filename):\n",
    "        os.makedirs('Frames_resize/'+filename)\n",
    "        vidcap = cv2.VideoCapture('video/'+filename+vidformat)\n",
    "        success,image = vidcap.read()\n",
    "        count = 0\n",
    "        while success:\n",
    "            if color:\n",
    "                img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            else:\n",
    "                img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            img = (cv2.resize(img, size, interpolation=cv2.INTER_CUBIC))\n",
    "            if saveHQ:\n",
    "                if not os.path.exists('Frames/'+filename):\n",
    "                    os.makedirs('Frames/'+filename)\n",
    "                cv2.imwrite('Frames/'+filename+'/frame%d.jpg' % count, image)     # save frame as JPEG file\n",
    "            cv2.imwrite('Frames_resize/'+filename+'/frame%d.jpg' % count, img)     # save frame as JPEG file \n",
    "            success,image = vidcap.read()\n",
    "            count += 1\n",
    "        print(count,'frames were generated')\n",
    "\n",
    "# Load all gray/color images into a 4d array(num_blocks,5,h,w)/5d array(num_blocks,3,5,h,w)\n",
    "# filename: video name\n",
    "# chunklen: temporal dimension\n",
    "# size: tuple(w*h)\n",
    "# lowres: if True, uses the resized images\n",
    "# color: whether or not to use color channels\n",
    "def frames2np(filename, chunklen, size=(192,108), lowres=True, color=True):\n",
    "    dim = 5 if color else 4\n",
    "    quality = 'lq' if lowres else 'hq'\n",
    "    if not os.path.isfile('data/train/'+filename+'_cl'+str(chunklen)+'_'+str(dim)+'d'+'_'+quality+'.npy'):        \n",
    "        if lowres:\n",
    "            path = 'Frames_resize/'+filename\n",
    "        else:\n",
    "            path = 'Frames/'+filename\n",
    "        filelist = sorted(glob.glob(os.path.join(path,'*.jpg')),key=lambda stri: int(re.findall('\\d+', stri)[0]))\n",
    "        num_chunks = len(filelist)//chunklen\n",
    "        filelist = filelist[:num_chunks*chunklen]\n",
    "        if color:\n",
    "            vid_np = np.zeros((num_chunks,chunklen,size[1],size[0],3))\n",
    "        else:\n",
    "            vid_np = np.zeros((num_chunks,chunklen,size[1],size[0]))\n",
    "        i = 0\n",
    "        j = 0\n",
    "        for frame in filelist:\n",
    "            if color:\n",
    "                image = cv2.imread(frame, cv2.IMREAD_COLOR)\n",
    "            else:\n",
    "                image = cv2.imread(frame, cv2.IMREAD_GRAYSCALE)\n",
    "            vid_np[i,j] = image\n",
    "            j += 1\n",
    "            if j % chunklen == 0:\n",
    "                j = 0\n",
    "                i += 1\n",
    "        if color:\n",
    "            vid_np = vid_np.reshape((num_chunks,3,chunklen,size[1],size[0]))\n",
    "        np.save('data/train/'+filename+'_cl'+str(chunklen)+'_'+str(dim)+'d'+'_'+quality,vid_np)\n",
    "    else:\n",
    "        vid_np = np.load('data/train/'+filename+'_cl'+str(chunklen)+'_'+str(dim)+'d'+'_'+quality+'.npy')\n",
    "    print('shape of numpy:',vid_np.shape)\n",
    "    return vid_np.shape[0]\n",
    "\n",
    "# generate 0 1 labels from framenums\n",
    "# filename: video name\n",
    "# chunklen: temporal dimension\n",
    "# numchunks: data size\n",
    "def framenum2labels(filename, chunklen, numchunks, threshold=1, csvformat=True):\n",
    "    if not os.path.isfile('labels/train/'+filename+'_cl'+str(chunklen)+'.npy'):\n",
    "        numframes = numchunks*chunklen\n",
    "        if not csvformat:\n",
    "            mat = scipy.io.loadmat('labels/'+filename+'.mat')\n",
    "            try:\n",
    "                framenums = np.array(mat['labels'][0])\n",
    "            except:\n",
    "                framenums = np.array(mat['frames'][0])\n",
    "            framelabels = np.zeros(numframes)\n",
    "            framelabels[framenums-1] = 1\n",
    "        else:\n",
    "            framelabels = []\n",
    "            with open('labels/'+filename+'.csv') as csvfile:\n",
    "                reader = csv.reader(csvfile)\n",
    "                for row in reader:\n",
    "                    framelabels.append(int(re.sub(\"\\D\", \"\", row[0])))\n",
    "            framelabels = np.array(framelabels[:numframes])\n",
    "        labels = 2*np.ones(numchunks)\n",
    "        for i in range(chunklen,numframes+chunklen,chunklen):\n",
    "            if np.sum(framelabels[i-chunklen:i]) > threshold-1:\n",
    "                labels[i//chunklen-1] = 1\n",
    "            else:\n",
    "                labels[i//chunklen-1] = 0\n",
    "        if 2 in labels:\n",
    "            sys.exit('Error: The labels contain label 2')\n",
    "        labels = np.column_stack((labels,np.arange(numchunks)))\n",
    "        np.save('labels/train/'+filename+'_cl'+str(chunklen),labels)\n",
    "    else:\n",
    "        labels = np.load('labels/train/'+filename+'_cl'+str(chunklen)+'.npy')\n",
    "    print('shape of labels:',labels.shape)\n",
    "\n",
    "# split the data into training and validation sets\n",
    "# filename: numpy file name without d\n",
    "# trainsplit: portion of training data\n",
    "# dim: 4 or 5\n",
    "def split(filename,trainsplit,dim,quality):\n",
    "    npfile = np.load('data/train/'+filename+'_'+str(dim)+'d'+'_'+quality+'.npy')\n",
    "    label = np.load('labels/train/'+filename+'.npy')\n",
    "    if trainsplit < 1 and trainsplit > 0:\n",
    "        size = len(npfile)\n",
    "        trainbatch = int(size*trainsplit)\n",
    "        indices = np.random.permutation(size)\n",
    "        npfile = npfile[indices]\n",
    "        label = label[indices]\n",
    "        train_data = npfile[:trainbatch]\n",
    "        train_labels = label[:trainbatch]\n",
    "        validation_data = npfile[trainbatch:]\n",
    "        validation_labels = label[trainbatch:]\n",
    "        np.save('data/train/'+filename+'_'+str(dim)+'d_'+quality+'_'+str(trainsplit), train_data)\n",
    "        np.save('data/validation/'+filename+'_'+str(dim)+'d_'+quality+'_'+str(trainsplit), validation_data)\n",
    "        np.save('labels/train/'+filename+'_'+str(trainsplit),train_labels)\n",
    "        np.save('labels/validation/'+filename+'_'+str(trainsplit),validation_labels)      \n",
    "        print('train shape:',train_data.shape, 'validation shape:',validation_data.shape)\n",
    "        print('numpy file:',filename+'_'+str(dim)+'d_'+quality+'_'+str(trainsplit))\n",
    "        print('label file:',filename+'_'+str(trainsplit))\n",
    "\n",
    "# runs the video and label throught he pipeline to produce training and validation datasets\n",
    "# by default, no validation dataset is generated\n",
    "# csv: True if the labels are in a csv\n",
    "def prepdata(filename, vidformat, chunklen, threshold=1, trainsplit=1, size=(192,108), csvformat=True, color=True, saveHQ=False, lowres=True):\n",
    "    vid2frames(filename, vidformat=vidformat, size=size, color=color, saveHQ=saveHQ)\n",
    "    numchunks = frames2np(filename, chunklen, size=size, lowres=lowres, color=color)\n",
    "    framenum2labels(filename, chunklen, numchunks, threshold=threshold, csvformat=csvformat)\n",
    "    if trainsplit != 1:\n",
    "        filename = filename+'_cl'+str(chunklen)\n",
    "        dim = 5 if color else 4\n",
    "        quality = 'lq' if lowres else 'hq'\n",
    "        split(filename,trainsplit,dim,quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine datasets and divide train and validation sets\n",
    "#### appenddata(filename1,filename2,chunklen,dim,quality,trainsplit=1)  \n",
    "filename1:  \n",
    "filename2:  \n",
    "chunklen: number of frames/chunk of video  \n",
    "dim: dimensions of data. 4 without color channels, 5 with color channels  \n",
    "quality: quality of data. 'lq' for low resolution, 'hq' for high resolution  \n",
    "trainsplit: train_data / total_data  \n",
    "#### Eg: appenddata('MVI_7500','MVI_7503',5,4,'lq',0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appenddata(filename1,filename2,chunklen,dim,quality,trainsplit=1):\n",
    "    if trainsplit != 1:\n",
    "        file1 = np.load('data/train/'+filename1+'_cl'+str(chunklen)+'_'+str(dim)+'d_'+quality+'_'+str(trainsplit)+'.npy')\n",
    "        file2 = np.load('data/train/'+filename2+'_cl'+str(chunklen)+'_'+str(dim)+'d_'+quality+'_'+str(trainsplit)+'.npy')\n",
    "        label1 = np.load('labels/train/'+filename1+'_cl'+str(chunklen)+'_'+str(trainsplit)+'.npy')\n",
    "        label2 = np.load('labels/train/'+filename2+'_cl'+str(chunklen)+'_'+str(trainsplit)+'.npy')\n",
    "        validation1 = np.load('data/validation/'+filename1+'_cl'+str(chunklen)+'_'+str(dim)+'d_'+quality+'_'+str(trainsplit)+'.npy')\n",
    "        validation2 = np.load('data/validation/'+filename2+'_cl'+str(chunklen)+'_'+str(dim)+'d_'+quality+'_'+str(trainsplit)+'.npy')\n",
    "        vlabel1 = np.load('labels/validation/'+filename1+'_cl'+str(chunklen)+'_'+str(trainsplit)+'.npy')\n",
    "        vlabel2 = np.load('labels/validation/'+filename2+'_cl'+str(chunklen)+'_'+str(trainsplit)+'.npy')\n",
    "        validation_set = np.append(validation1, validation2, axis=0)\n",
    "        np.save('data/validation/'+filename1+'_'+filename2+'_cl'+str(chunklen)+'_'+str(dim)+'d_'+quality+'_'+str(trainsplit),validation_set)\n",
    "        np.save('labels/validation/'+filename1+'_'+filename2+'_cl'+str(chunklen)+'_'+str(trainsplit),np.append(vlabel1, vlabel2, axis=0))\n",
    "    else:\n",
    "        file1 = np.load('data/train/'+filename1+'_cl'+str(chunklen)+'_'+str(dim)+'d_'+quality+'.npy')\n",
    "        file2 = np.load('data/train/'+filename2+'_cl'+str(chunklen)+'_'+str(dim)+'d_'+quality+'.npy')\n",
    "        label1 = np.load('labels/train/'+filename1+'_cl'+str(chunklen)+'.npy')\n",
    "        label2 = np.load('labels/train/'+filename2+'_cl'+str(chunklen)+'.npy')\n",
    "    train_set = np.append(file1, file2, axis=0)\n",
    "    np.save('data/train/'+filename1+'_'+filename2+'_cl'+str(chunklen)+'_'+str(dim)+'d_'+quality+'_'+str(trainsplit),train_set)\n",
    "    np.save('labels/train/'+filename1+'_'+filename2+'_cl'+str(chunklen)+'_'+str(trainsplit),np.append(label1, label2, axis=0))\n",
    "    print('train shape:',train_set.shape, 'validation shape:',validation_set.shape)\n",
    "    print('numpy file:',filename1+'_'+filename2+'_cl'+str(chunklen)+'_'+str(dim)+'d_'+quality+'_'+str(trainsplit))\n",
    "    print('label file',filename1+'_'+filename2+'_cl'+str(chunklen)+'_'+str(trainsplit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### annotate videos  \n",
    "#### annotate(video, vidformat, x=1, save=True, showtimes=False)  \n",
    "video: name of video  \n",
    "vidformat: format like avi/mov/mp4  \n",
    "x: speed  \n",
    "save: save generated labels  \n",
    "showtimes: show timestamps when mosquito present\n",
    "#### return: generated labels  \n",
    "#### Eg: annotate('MVI_7500','mov',showtimes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate(video, vidformat, x=1, save=True, showtimes=False):\n",
    "\n",
    "    def onSlide(pos):\n",
    "        slider_position[0] = pos\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES,pos)\n",
    "\n",
    "    def prev_next(action, current_state):\n",
    "        end = False\n",
    "        if action == ord('p'):\n",
    "            pass\n",
    "        elif action == ord('d'):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                end = True\n",
    "                return end, current_state\n",
    "            cv2.imshow('frame',frame)\n",
    "            slider_position[0] += 1\n",
    "            cv2.setTrackbarPos('position', 'frame', slider_position[0])\n",
    "            annotation_list[int(cap.get(cv2.CAP_PROP_POS_FRAMES))-1] = current_state\n",
    "            action = cv2.waitKey(0)\n",
    "            end, current_state = prev_next(action, current_state)\n",
    "        elif action == ord('a'):\n",
    "            onSlide(slider_position[0]-2)\n",
    "            ret, frame = cap.read()\n",
    "            cv2.imshow('frame',frame)\n",
    "            slider_position[0] += 1\n",
    "            cv2.setTrackbarPos('position', 'frame', slider_position[0])\n",
    "            action = cv2.waitKey(0)\n",
    "            end, current_state = prev_next(action, current_state)\n",
    "        elif action == ord(' '):\n",
    "            current_state = not current_state\n",
    "            print('Current state',current_state)\n",
    "            annotation_list[int(cap.get(cv2.CAP_PROP_POS_FRAMES))-1] = current_state\n",
    "            action = cv2.waitKey(0)\n",
    "            end, current_state = prev_next(action, current_state)\n",
    "        return end, current_state\n",
    "\n",
    "    current_state = False\n",
    "    slider_position = [0]\n",
    "    cv2.namedWindow('frame',cv2.WINDOW_NORMAL)\n",
    "    cap = cv2.VideoCapture('video/'+video+'.'+vidformat)\n",
    "    frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    annotation_list = np.zeros(frames)\n",
    "    if frames != 0:\n",
    "        cv2.createTrackbar('position', 'frame', slider_position[0], frames, onSlide)\n",
    "    while(True):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        cv2.imshow('frame',frame)\n",
    "        slider_position[0] += 1\n",
    "        cv2.setTrackbarPos('position', 'frame', slider_position[0])\n",
    "        annotation_list[int(cap.get(cv2.CAP_PROP_POS_FRAMES))-1] = current_state\n",
    "        key = cv2.waitKey(33//x)\n",
    "\n",
    "        if key & 0xFF == ord(' '):\n",
    "            current_state = not current_state\n",
    "        if key & 0xFF == ord('p'):\n",
    "            action = cv2.waitKey(0)\n",
    "            end, current_state = prev_next(action, current_state)\n",
    "            if end:\n",
    "                break\n",
    "        if key == 27:#if ESC is pressed, exit loop\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    annotation_list = annotation_list.astype(int)\n",
    "    if save:\n",
    "        np.savetxt('labels/'+video+'.csv',annotation_list,delimiter=',',fmt='%d')\n",
    "    txt = ''\n",
    "    for i in range(0, frames, 30):\n",
    "        if sum(annotation_list[i:i+30]):\n",
    "            txt += '('+str(i//1800)+':'+str((i//30)%60)+') // '\n",
    "    with open('labels/'+video+'.txt', \"w\") as text_file:\n",
    "        text_file.write(txt)\n",
    "    if showtimes:\n",
    "        print(txt)\n",
    "    return annotation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.8\n",
      "shape of numpy: (629, 5, 108, 192)\n",
      "shape of labels: (629, 2)\n",
      "train shape: (503, 5, 108, 192) validation shape: (126, 5, 108, 192)\n",
      "numpy file: MVI_7500_cl5_4d_lq_0.8\n",
      "label file: MVI_7500_cl5_0.8\n"
     ]
    }
   ],
   "source": [
    "prepdata('MVI_7500','.mov',5,1,0.8,color=False,csvformat=True,saveHQ=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4662 frames were generated\n",
      "shape of numpy: (932, 5, 108, 192)\n",
      "shape of labels: (932, 2)\n",
      "train shape: (745, 5, 108, 192) validation shape: (187, 5, 108, 192)\n",
      "numpy file: MVI_7503_cl5_4d_lq_0.8\n",
      "label file: MVI_7503_cl5_0.8\n"
     ]
    }
   ],
   "source": [
    "prepdata('MVI_7503','.mov',5,1,0.8,color=False,csvformat=True,saveHQ=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2991 frames were generated\n",
      "shape of numpy: (598, 5, 108, 192)\n",
      "shape of labels: (598, 2)\n",
      "train shape: (478, 5, 108, 192) validation shape: (120, 5, 108, 192)\n",
      "numpy file: MVI_7512_cl5_4d_lq_0.8\n",
      "label file: MVI_7512_cl5_0.8\n"
     ]
    }
   ],
   "source": [
    "prepdata('MVI_7512','.mov',5,1,0.8,color=False,csvformat=True,saveHQ=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9389 frames were generated\n",
      "shape of numpy: (1877, 5, 108, 192)\n",
      "shape of labels: (1877, 2)\n",
      "train shape: (1501, 5, 108, 192) validation shape: (376, 5, 108, 192)\n",
      "numpy file: MVI_7507_cl5_4d_lq_0.8\n",
      "label file: MVI_7507_cl5_0.8\n"
     ]
    }
   ],
   "source": [
    "prepdata('MVI_7507','.mov',5,1,0.8,color=False,csvformat=True,saveHQ=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy file: MVI_7500_MVI_7503_cl5_4d_lq_0.8\n",
      "label file MVI_7500_MVI_7503_cl5_0.8\n"
     ]
    }
   ],
   "source": [
    "appenddata('MVI_7500','MVI_7503',5,4,'lq',0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy file: MVI_7500_MVI_7503_MVI_7512_cl5_4d_lq_0.8\n",
      "label file MVI_7500_MVI_7503_MVI_7512_cl5_0.8\n"
     ]
    }
   ],
   "source": [
    "appenddata('MVI_7500_MVI_7503','MVI_7512',5,4,'lq',0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (3227, 5, 108, 192) validation shape: (809, 5, 108, 192)\n",
      "numpy file: MVI_7500_MVI_7503_MVI_7512_MVI_7507_cl5_4d_lq_0.8\n",
      "label file MVI_7500_MVI_7503_MVI_7512_MVI_7507_cl5_0.8\n"
     ]
    }
   ],
   "source": [
    "appenddata('MVI_7500_MVI_7503_MVI_7512','MVI_7507',5,4,'lq',0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (2749, 5, 108, 192) validation shape: (689, 5, 108, 192)\n",
      "numpy file: MVI_7500_MVI_7503_MVI_7507_cl5_4d_lq_0.8\n",
      "label file MVI_7500_MVI_7503_MVI_7507_cl5_0.8\n"
     ]
    }
   ],
   "source": [
    "appenddata('MVI_7500_MVI_7503','MVI_7507',5,4,'lq',0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state True\n",
      "Current state False\n",
      "(0:5) // (0:6) // (0:7) // (0:8) // \n"
     ]
    }
   ],
   "source": [
    "framelabels = annotate('MVI_7507','mov',x=2,showtimes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "framelabels[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt='(0:2) // (0:3) // (0:8) // (0:13) // (0:19) // (0:20) // (0:24) // (0:25) // (0:26) // (0:28) // (0:29) // (0:30) // (0:54) // (0:55) // (0:56) // (1:5) // (1:6) // (1:8) // (1:9) // (1:10) // (1:11) // (1:12) // (1:13) // (1:14) // (1:22) // (1:23) // (1:24) // (1:25) // (1:26) // (1:27) // (1:28) // (1:32) // (1:33) // (1:34) // (1:37) // (1:38) // (1:39) // (1:40) // (1:41) // (1:42) // (1:43) // (1:44) // '\n",
    "with open(\"labels/MVI_7500.txt\", \"w\") as text_file:\n",
    "    text_file.write(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
